---

title: "Community Bonding Period (Week 1, 2 and 3)"
comments: true
read_time: true

---

## What is it?

The very first phase of GSoC period is the Community Bonding Period, in which you get to know your community and get familiar with their code base and work style. Community bonding period is all about, as the name suggests bonding with org's community. This is a 3-week period where students learn about the software development practices of the organisation and share their ideas about the project.


## Week 1

During this week, I scheduled my first video call with my mentors. We shared a little bit about ourselves. We discussed about the scope of this project and what are the different directions of improvment which can be done during the course of this project tenure.

I spent the remaining time of this week in knowing about DBpedia and the role & other whereabouts of my project. This included,

* Reading about SPARQL
* A thorough read of NSpM model and why/how it works
* Learning more about Git procedures 
* Setting up a communication channel for the GSoC period (we chose slack)


## Week 2

I spent this week to understand the implementation of the code and go through entire implementation of the end-to-end NSpM architecture. Before kicking off the coding period, its better to get your basics clear about the current model in order to move forward and making improvments. We also had another telco, discussing our aim for the coming week.

So, I completed the following during week 2:

* Set up neural-qa model on local machine
* Set up a new branch, gsoc-aman, which will serve as my GSoC project repository
* Train and test the model for class dbo:Monument
* Found out a couple of bugs/scope of improvements during testing

## Week 3

During this week, I learned how to query DBpedia using SPARQL. I followed a couple of tutorials to learn SPARQL query language. I will require sparql queries to extract metadata about properties of classes, such as label, range and domain of each property.

This week, my task is to learn SPARQL and also write python scripts to fetch metadata about large(important) classes, for eg: dbo:Place. This metadata is supposed to include metadata about all the properties of a given class, sorted in decreasing order of a property's importance.

We use a baseline idea of number of occurence of a property to define it's importance.

Tasks for the week:

* Learn SPARQL
* Understand different graph IRIs and how to use them
* Build python scripts to automatically fetch metadata and store it

